# ğŸ¤– AI Integration Lab

Bem-vindo ao **AI Integration Lab**! Este repositÃ³rio Ã© uma coleÃ§Ã£o de exemplos prÃ¡ticos e tutoriais para integrar InteligÃªncia Artificial em suas aplicaÃ§Ãµes. Focamos em demonstraÃ§Ãµes hands-on usando ferramentas modernas como **Ollama**, **Docker**, e APIs REST.

## ğŸš€ Objetivo

Capacitar desenvolvedores e entusiastas a entender, implementar e integrar soluÃ§Ãµes de IA em aplicaÃ§Ãµes reais, com foco em:
- Deploy de modelos locais com Ollama
- IntegraÃ§Ã£o via APIs REST
- AutomaÃ§Ã£o com Docker Compose
- Casos de uso prÃ¡ticos

## ğŸ“š ConteÃºdo

Este repositÃ³rio estÃ¡ organizado em exemplos prÃ¡ticos. Cada exemplo contÃ©m:

- ğŸ³ ConfiguraÃ§Ãµes Docker Compose prontas para uso
- ğŸ“¡ Exemplos de integraÃ§Ã£o via API
- ğŸ§ª CÃ³digos de exemplo em Python/JavaScript
- ğŸ“– DocumentaÃ§Ã£o detalhada
- ğŸ—‚ ReferÃªncias e links Ãºteis

### Exemplos disponÃ­veis:

1. **ğŸš€ Ollama com Docker Compose**
   - Deploy local do Ollama
   - ConfiguraÃ§Ã£o de modelos
   - Primeiras queries via API

2. **ğŸ”— IntegraÃ§Ã£o REST API**
   - Exemplos de clientes HTTP
   - AutenticaÃ§Ã£o e rate limiting
   - Tratamento de respostas

3. **ğŸ¤– Chatbots e Assistantes**
   - IntegraÃ§Ã£o com aplicaÃ§Ãµes web
   - Processamento de contexto
   - GeraÃ§Ã£o de respostas inteligentes

4. **ğŸ“Š AnÃ¡lise de Dados com IA**
   - Processamento de texto
   - ClassificaÃ§Ã£o de documentos
   - ExtraÃ§Ã£o de insights

5. **ğŸ”„ AutomaÃ§Ã£o e Workflows**
   - IntegraÃ§Ã£o com CI/CD
   - Processamento em lote
   - Monitoramento de performance

## ğŸ›  PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de ter instalado:

- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)
- [Python 3.8+](https://www.python.org/downloads/)
- [Git](https://git-scm.com/downloads)

## ğŸš€ Primeiro Exemplo: Ollama com Docker Compose

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/seu-usuario/ai-integration-lab.git
cd ai-integration-lab
```

### 2. Inicie o Ollama
```bash
docker-compose up -d ollama
```

### 3. FaÃ§a sua primeira query
```bash
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama2",
    "prompt": "OlÃ¡! Como vocÃª pode me ajudar hoje?",
    "stream": false
  }'
```

### 4. Exemplo em Python
```python
import requests
import json

def query_ollama(prompt, model="llama2"):
    url = "http://localhost:11434/api/generate"
    data = {
        "model": model,
        "prompt": prompt,
        "stream": False
    }
    
    response = requests.post(url, json=data)
    return response.json()

# Teste
response = query_ollama("Explique o que Ã© machine learning em 2 frases")
print(response['response'])
```

## ğŸ“ Estrutura do Projeto

```
ai-integration-lab/
â”œâ”€â”€ docker-compose.yml          # ConfiguraÃ§Ã£o do Ollama
â”œâ”€â”€ examples/                   # Exemplos prÃ¡ticos
â”‚   â”œâ”€â”€ python/                # CÃ³digos Python
â”‚   â”œâ”€â”€ javascript/            # CÃ³digos JavaScript
â”‚   â””â”€â”€ bash/                  # Scripts bash
â”œâ”€â”€ docs/                      # DocumentaÃ§Ã£o
â””â”€â”€ README.md                  # Este arquivo
```

## ğŸ”§ ConfiguraÃ§Ã£o

### Docker Compose
O arquivo `docker-compose.yml` inclui:
- **Ollama**: Servidor local de modelos de IA
- **Redis** (opcional): Cache para respostas
- **Nginx** (opcional): Proxy reverso

### VariÃ¡veis de Ambiente
Crie um arquivo `.env`:
```env
OLLAMA_HOST=0.0.0.0
OLLAMA_PORT=11434
REDIS_URL=redis://redis:6379
```

## ğŸ“– DocumentaÃ§Ã£o

- [Ollama API Reference](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [Docker Compose Guide](https://docs.docker.com/compose/)
- [Python Requests](https://requests.readthedocs.io/)

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ†˜ Suporte

- ğŸ“§ Email: seu-email@exemplo.com
- ğŸ’¬ Issues: [GitHub Issues](https://github.com/seu-usuario/ai-integration-lab/issues)
- ğŸ“š Wiki: [DocumentaÃ§Ã£o completa](https://github.com/seu-usuario/ai-integration-lab/wiki)

---

â­ Se este projeto te ajudou, considere dar uma estrela no repositÃ³rio!
